<!DOCTYPE HTML>
<html lang="en"><head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

  <title>Yijia Weng</title>
  
  <meta name="author" content="Yijia Weng">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  
  <link rel="stylesheet" type="text/css" href="stylesheet.css">
  <link rel="icon" type="image/png" href="images/floral_icon.png">
</head>

<body>
  <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
    <tr style="padding:0px">
      <td style="padding:0px">
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr style="padding:0px">
            <td style="padding:2.5%;width:63%;vertical-align:middle">
              <p style="text-align:center">
                <name>Yijia Weng | 翁伊嘉</name>
              </p>
              <p>I am a rising fifth-year Ph.D. student in computer science at Stanford University, advised by Prof. <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>. Previously, I obtained my B.S. in Computer Science from Turing Class, Peking University, advised by Prof. <a href="http://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>. I also had the privilege of working closely with Prof. <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a> at Stanford, Prof. <a href="https://cseweb.ucsd.edu/~haosu/">Hao Su</a> at UCSD, and Prof. <a href="https://hughw19.github.io/">He Wang</a> at Peking University. I've had a wonderful time pursuing research internships at <a href="https://research.adobe.com/">Adobe Research</a>, <a href="https://www.nvidia.com/en-us/research/research-areas/">NVIDIA Research</a>, and <a href="https://deepmind.google/">Google Deepmind</a>.
              </p>
              <p style="text-align:center">
                <a href="mailto:yijiaw@stanford.edu">Email</a> &nbsp/&nbsp
                <a href="https://scholar.google.com/citations?hl=en&user=yeuv8L4AAAAJ">Google Scholar</a> &nbsp/&nbsp
                <a href="https://github.com/halfsummer11/">Github</a>
              </p>
            </td>
            <td style="padding:2.5%;width:40%;max-width:40%">
              <a href="images/yijia.png"><img style="width:100%;max-width:100%" alt="profile photo" src="images/yijia.png" class="hoverZoomLink"></a>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Research</heading>
              <p>
			  My research interests lie in 3D computer vision, with a focus on reconstructing the 3D world with efficient, interaction-aware, and semantically meaningful representations. 
              </p>
            </td>
          </tr>
        </tbody></table>
        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>

		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
			  <video controls autoplay muted playsinline loop style="width:100%">
			  <source src="images/mosca.mp4" > </video>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion Scaffolds</papertitle>
              <br>
			  <a href="https://www.cis.upenn.edu/~leijh/">Jiahui Lei</a>,
              <strong>Yijia Weng</strong>,
			  <a href="https://adamharley.com/">Adam W. Harley</a>,
			  <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>,
			  <a href="https://www.cis.upenn.edu/~kostas/">Kostas Daniilidis</a>
			  <br>
              <em>CVPR</em>, 2025
              <br>
              <a href="https://www.cis.upenn.edu/~leijh/projects/mosca/">project page</a>  /
			  <a href="https://arxiv.org/abs/2405.17421">arXiv</a> /
			  <a href="https://github.com/JiahuiLei/MoSca">code</a>
              <p></p>
            </td>
         </tr>

		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/feature4x.png' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Feature4X: Bridging Any Monocular Video to 4D Agentic AI with Versatile Gaussian Feature Fields</papertitle>
              <br>
			  <a href="https://shijiezhou-ucla.github.io/">Shijie Zhou*</a>,
			  <a href="https://rhfeiyang.github.io">Hui Ren*</a>,
              <strong>Yijia Weng</strong>,
			  <a href="https://www.linkedin.com/in/shuwang-zhang">Shuwang Zhang</a>,
			  <a href="https://zhenwangwz.github.io/">Zhen Wang</a>,
			  <a href="https://ir1d.github.io/">Dejia Xu</a>,
			  <a href="https://zhiwenfan.github.io/">Zhiwen Fan</a>,
			  <a href="https://scholar.google.com/citations?user=LkpA-L0AAAAJ&hl=en">Suya You</a>,
			  <a href="https://vita-group.github.io/">Zhangyang Wang</a>,
			  <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>,
			  <a href="https://samueli.ucla.edu/people/achuta-kadambi/">Achuta Kadambi</a>
			  <br>
              <em>CVPR</em>, 2025
              <br>
              <a href="https://feature4x.github.io/">project page</a>  /
			  <a href="https://arxiv.org/abs/2503.20776">arXiv</a> /
			  <a href="https://github.com/ShijieZhou-UCLA/Feature4X">code</a>
              <p></p>
            </td>
         </tr>




		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
			<video controls autoplay muted playsinline loop style="width:100%">
			<source src="images/real2code-website-video.mp4" > </video>
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Real2Code: Reconstruct Articulated Objects via Code Generation</papertitle>
              <br>
			  <a href="https://mandizhao.github.io">Mandi Zhao</a>,
			  <strong>Yijia Weng</strong>,
              <a href="https://dornik.github.io">Dominik Bauer</a>,
              <a href="https://shurans.github.io/">Shuran Song</a>
			  <br>
              <em>ICLR</em>, 2025
              <br>
              <a href="https://real2code.github.io/">project page</a>  /
			  <a href="https://arxiv.org/abs/2406.08474">arXiv</a> /
			  <a href="https://github.com/MandiZhao/real2code">code</a>
              <p></p>
            </td>
         </tr>



		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/aograsp.gif' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>AO-Grasp: Articulated Object Grasp Generation</papertitle>
              <br>
			  <a href="https://carlotapares.com/">Carlota Parés Morlans*</a>,
			  <a href="https://clairelc.github.io/">Claire Chen*</a>,
              <strong>Yijia Weng</strong>,
			  <a href="https://scholar.google.com/citations?user=AIwe9q0AAAAJ&hl=en">Michelle Yi</a>, 
			  <a href="https://www.linkedin.com/in/yuyingblairhuang/">Yuying Huang</a>,
			  <a href="https://rl.uni-freiburg.de/people/heppert">Nick Heppert</a>,
			  <a href="https://alexzhou907.github.io/">Linqi Zhou</a>,
			  <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>,
			  <a href="https://web.stanford.edu/~bohg/">Jeannette Bohg</a>
			  <br>
              <em>IROS</em>, 2024
              <br>
              <a href="https://stanford-iprl-lab.github.io/ao-grasp/">project page</a>  /
			  <a href="https://arxiv.org/abs/2310.15928">arXiv</a> /
			  <a href="https://github.com/stanford-iprl-lab/ao-grasp">code</a>
              <p></p>
            </td>
         </tr>


		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/digital-twins.png' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Neural Implicit Representation for Building Digital Twins of Unknown Articulated Objects</papertitle>
              <br>
              <strong>Yijia Weng</strong>,
			  <a href="https://research.nvidia.com/person/bowen-wen">Bowen Wen</a>,
			  <a href="https://research.nvidia.com/person/jonathan-tremblay">Jonathan Tremblay</a>,
			  <a href="https://research.nvidia.com/person/valts-blukis">Valts Blukis</a>,
			  <a href="https://homes.cs.washington.edu/~fox/">Dieter Fox</a>,
              <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>,
			  <a href="https://research.nvidia.com/person/stan-birchfield">Stan Birchfield</a>
			  <br>
              <em>CVPR</em>, 2024
              <br>
              <a href="https://nvlabs.github.io/DigitalTwinArt/">project page</a>  /
			  <a href="https://arxiv.org/abs/2404.01440">arXiv</a> /
			  <a href="https://github.com/NVlabs/DigitalTwinArt">code</a>
              <p></p>
            </td>
         </tr>


		<tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/eigen-length.png' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Towards Learning Geometric Eigen-Lengths Crucial for Fitting Tasks</papertitle>
              <br>
              <strong>Yijia Weng</strong>,
			  <a href="https://kaichun-mo.github.io/">Kaichun Mo </a>,
			  <a href="https://rshi.top/">Ruoxi Shi</a>,
			  <a href="https://yanchaoyang.github.io/">Yanchao Yang</a>,
              <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>
			  <br>
              <em>ICML</em>, 2023
              <br>
              <a href="https://yijiaweng.github.io/geo-eigen-length/">project page</a> /
              <a href="https://arxiv.org/abs/2312.15610">arXiv</a>
              <p></p>
            </td>
         </tr>


        <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/equipose.png' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Leveraging SE(3) Equivariance for Self-supervised Category-Level Object Pose Estimation from Point Clouds</papertitle>
              <br>
              <a href="http://dragonlong.github.io/">Xiaolong Li</a>,
              <strong>Yijia Weng</strong>,
              <a href="https://ericyi.github.io/">Li Yi</a>,
              <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>,
              <a href="https://ece.vt.edu/people/profile/abbott">A. Lynn Abbott</a>,
              <a href="https://www.cs.columbia.edu/~shurans/">Shuran Song</a>,
              <a href="https://hughw19.github.io/">He Wang</a>
              <br>
              <em>NeurIPS</em>, 2021
              <br>
              <a href="https://dragonlong.github.io/equi-pose/">project page</a> /
              <a href="https://arxiv.org/abs/2111.00190">arXiv</a>
              <p></p>
            </td>
         </tr>


         <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/captra.gif' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>CAPTRA: CAtegory-level Pose Tracking for Rigid and Articulated Objects from Point Clouds</papertitle>
              <br>
              <strong>Yijia Weng*</strong>,
              <a href="https://hughw19.github.io/">He Wang*</a>,
              <a href="https://github.com/bamboosdu">Qiang Zhou</a>,
              <a href="https://yzqin.github.io">Yuzhe Qin</a>,
              <a href="https://geometry.stanford.edu/member/duanyq19/index.html">Yueqi Duan</a>,
              <a href="https://fqnchina.github.io">Qingnan Fan</a>,
              <br>
              <a href="https://cfcs.pku.edu.cn/baoquan">Baoquan Chen</a>,
              <a href="https://cseweb.ucsd.edu/~haosu">Hao Su</a>,
              <a href="https://geometry.stanford.edu/?member=guibas">Leonidas Guibas</a>
              <br>
              <em>ICCV</em>, 2021 <span class="badge">Oral Presentation</span>
              <br>
              <a href="https://yijiaweng.github.io/CAPTRA/">project page</a> /
              <a href="https://youtu.be/EkcCEj7gZGg">video</a> /
              <a href="https://arxiv.org/abs/2104.03437">arXiv</a> /
              <a href="https://github.com/halfsummer11/CAPTRA">code</a>
              <p></p>
            </td>
         </tr>

          <tr>
            <td style="padding:10px;width:30%;vertical-align:middle">
              <img src='images/mst.gif' width="100%">
            </td>
            <td style="padding:20px;width:70%;vertical-align:middle">
              <papertitle>Unpaired Motion Style Transfer from Video to Animation</papertitle>
              <br>

              <a href="http://kfiraberman.github.io/">Kfir Aberman*</a>,
              <strong>Yijia Weng*</strong>,
              <a href="https://www.cse.huji.ac.il/~danix/">Dani Lischinski</a>,
              <a href="https://danielcohenor.com/">Daniel Cohen-Or</a>,
              <a href="https://cfcs.pku.edu.cn/baoquan">Baoquan Chen</a>
              <br>
							<em>SIGGRAPH</em>, 2020
              <br>
              <a href="https://deepmotionediting.github.io/style_transfer">project page</a> /
              <a href="https://youtu.be/m04zuBSdGrc">video</a> /
              <a href="https://arxiv.org/abs/2005.05751">arXiv</a> /
              <a href="https://github.com/DeepMotionEditing/deep-motion-editing">code</a>
              <p></p>
            </td>
          </tr>




        </tbody></table>

        <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20"><tbody>
          <tr>
            <td>
              <heading>Experience</heading>
            </td>
          </tr>
        </tbody></table>
        <table width="100%" align="center" border="0" cellpadding="10"><tbody>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/stanford_university.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Stanford University</b>, CA
              <br> 2021.09 - Present
              <br>
              <br> <b>Ph.D. Student in Computer Science</b>
              <br> Advisor: Prof. <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>
            </td>
          </tr>

		 <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/deepmind.png", width="100%"></td>
            <td width="80%" valign="center">
              <b>Google Deepmind</b>, CA
              <br> 2024.07 - 2024.12
              <br>
              <br> <b>Student Researcher</b>
            </td>
          </tr>
		 <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/nvidia.png", width="100%"></td>
            <td width="80%" valign="center">
              <b>NVIDIA Research</b>, WA
              <br> 2023.06 - 2023.12
              <br>
              <br> <b>Research Intern</b>
            </td>
          </tr>
		 <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/adobe.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Adobe Research</b>, CA
              <br> 2022.06 - 2022.09
              <br>
              <br> <b>Research Intern</b>
            </td>
          </tr>



          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/peking_university.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Peking University</b>, China
              <br> 2017.09 - 2021.07
              <br>
              <br> <b>B.S. in Computer Science</b>, Turing Class
              <br> Advisor: Prof. <a href="http://cfcs.pku.edu.cn/baoquan/">Baoquan Chen</a>
            </td>
          </tr>
          <tr>
            <td style="padding-left:20px;padding-right:20px;width:20%;vertical-align:middle"><img src="images/stanford_university.png", width="90%"></td>
            <td width="80%" valign="center">
              <b>Stanford University</b>, CA
              <br> 2020.03 - 2020.11
              <br>
              <br> <b>Visiting Research Student</b> through the <a href="https://engineering.stanford.edu/students-academics/programs/global-engineering-programs/chinese-ugvr">UGVR program</a>
              <br> Advisor: Prof. <a href="https://geometry.stanford.edu/member/guibas/">Leonidas Guibas</a>
            </td>
          </tr>

        </tbody></table>

        <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
            <td style="padding:20px;width:100%;vertical-align:middle">
              <heading>Miscellaneous</heading>
              <p>
                I was quite into competitive programming&#128187; and used to compete in Olympiad in Informatics and <a href="https://icpc.global/">International Collegiate Programming Contest (ICPC)</a>&#127941;.
                Now I also train high school students back at home. Solving those brain teasers is always fun!
                <br> In my spare time, I enjoy dancing&#128131;, cooking&#127859;, concerts&#127915;, musicals&#127917;, and learning foreign languages&#127467;&#127479;&#127472;&#127479;.
              </p>
            </td>
          </tr>
        </tbody></table>

		<table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
          <tr>
            <td style="padding:0px">
              <br>
              <p style="text-align:right;font-size:small;">
              Template stolen from <a href="https://jonbarron.info/">Jon Barron</a>. Thanks for stopping by :)
              <br> Last updated: Jul 14, 2025
              </p>
            </td>
          </tr>
        </tbody></table>
      </td>
    </tr>
  </table>
</body>

</html>
